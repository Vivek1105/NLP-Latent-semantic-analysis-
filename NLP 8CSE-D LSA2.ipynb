{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eccc24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d9bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\"The amount of polution is increasing day by day\",\n",
    "           \"The concert was just great\",\n",
    "           \"I love to see Gordon Ramsay cook\",\n",
    "           \"Google is introducing a new technology\",\n",
    "           \"AI Robots are examples of great technology present today\",\n",
    "           \"All of us were singing in the concert\",\n",
    "           \"We have launch campaigns to stop pollution and global warming\"]\n",
    "\n",
    "dataset = [line.lower() for line in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17204cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Tfidf Model\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb50fa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t0.3211483974289089\n",
      "  (0, 9)\t0.6422967948578178\n",
      "  (0, 17)\t0.3211483974289089\n",
      "  (0, 19)\t0.2665807498646048\n",
      "  (0, 26)\t0.3211483974289089\n",
      "  (0, 24)\t0.2278643877752444\n",
      "  (0, 2)\t0.3211483974289089\n",
      "  (0, 34)\t0.2278643877752444\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the Tfidf Model\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b77f2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=4, n_iter=100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the SVD\n",
    "lsa = TruncatedSVD(n_components = 4, n_iter = 100)\n",
    "lsa.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ed828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Column of V\n",
    "row1 = lsa.components_[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "835ee82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Concept Dictionary Creation\n",
    "concept_words = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "152f6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the concepts\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i,comp in enumerate(lsa.components_):\n",
    "    componentTerms = zip(terms,comp)\n",
    "    sortedTerms = sorted(componentTerms,key=lambda x:x[1],reverse=True)\n",
    "    sortedTerms = sortedTerms[:10]\n",
    "    concept_words[\"Concept \"+str(i)] = sortedTerms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fae27ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concept 0:\n",
      "1.1297395470753941\n",
      "1.4959427190164034\n",
      "0\n",
      "0.18383834567413443\n",
      "0.7797604325216754\n",
      "1.3733655989909492\n",
      "0\n",
      "\n",
      "Concept 1:\n",
      "0\n",
      "0\n",
      "1.8337467336425444\n",
      "0\n",
      "0\n",
      "0\n",
      "1.285014232418706\n",
      "\n",
      "Concept 2:\n",
      "0.6242100916830909\n",
      "0\n",
      "0\n",
      "1.744070338307561\n",
      "0.8334337554863636\n",
      "0\n",
      "0\n",
      "\n",
      "Concept 3:\n",
      "2.2015937554478873\n",
      "0.1272421318069432\n",
      "0\n",
      "0.21264455202450164\n",
      "0\n",
      "0.2965820743887402\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Sentence Concepts\n",
    "for key in concept_words.keys():\n",
    "    sentence_scores = []\n",
    "    for sentence in dataset:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        score = 0\n",
    "        for word in words:\n",
    "            for word_with_score in concept_words[key]:\n",
    "                if word == word_with_score[0]:\n",
    "                    score += word_with_score[1]\n",
    "        sentence_scores.append(score)\n",
    "    print(\"\\n\"+key+\":\")\n",
    "    for sentence_score in sentence_scores:\n",
    "        print(sentence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceed5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
